---
title: "Homework 5"
author: "Josh Liu"
format: html
editor: visual
editor_options: 
  chunk_output_type: inline
---

```{r}
#| warning: false
#install.packages("gt")
#install.packages("plotly")
#nstall.packages("lme4")
#install.packages("lmerTest")
library(tidyverse)
library(gt)
library(plotly)
library(lme4)
library(lmerTest)
```


Importing Data


```{r}

#directory <- "C:\\Users\\Matt\\Dropbox\\Research\\delong maze\\"
here::i_am("analysis/homework-5-joshliu17.qmd")
library(here)

d <- read.csv(here("data/delong maze 40Ss.csv"), 
              header = 0, sep = ",", comment.char = "#", strip.white = T,
              col.names = c("Index","Time","Counter","Hash","Owner","Controller","Item","Element","Type","Group","FieldName","Value","WordNum","Word","Alt","WordOn","CorrWord","RT","Sent","TotalTime","Question","Resp","Acc","RespRT"));

```


## Prediction in the Maze

The study investigates whether comprehenders engage in predictive processing by pre-activating the phonetic form of upcoming expected words. The hypothesis is that if comprehenders predict upcoming words, there should be evidence of pre-activation of the expected word's form, including its required indefinite article (a/an). The key manipulation involves sentence contexts that strongly constrain for an expected noun (e.g. "The day was breezy so the boy went outside to fly...") versus an unexpected noun. The expected and unexpected nouns require different indefinite article forms (a kite vs. an airplane). Some example sentences from the stimuli: Expected: "The highlight of Jack's trip to India was when he got to ride an elephant in the parade." Unexpected: "The highlight of Jack's trip to India was when he got to ride a bicycle in the parade." "You never forget how to ride an elephant once you've learned." The study uses an A-maze task which presents sentences word-by-word with participants having to choose the correct word between two alternatives at each step. Response times on the article (a/an) and noun are measured to see if they are slower for unexpected compared to expected continuations, which would suggest pre-activation of the expected word's form. background stuff. the hypothesis was...

## Codebook/Data Dictionary

These are the variables in the raw data.

| Variable   | Description                                     |
|------------|-------------------------------------------------|
| Index      | Results Index                                   |
| Time       | Time                                            |
| Counter    | Counter                                         |
| Hash       | Participant Identifier                          |
| Owner      | Logged in as experiment owner? (Yes or No)      |
| Controller | Controller Name                                 |
| Item       | Item Number                                     |
| Element    | Element Number                                  |
| Type       | Type                                            |
| Group      | Group                                           |
| FieldName  | Field Name                                      |
| Value      | Field Value                                     |
| WordNum    | Word Number                                     |
| Word       | Word                                            |
| Alt        | Alternative                                     |
| WordOn     | Word on (0=left, 1=right)                       |
| CorrWord   | Correct                                         |
| RT         | Reading time to first answer                    |
| Sent       | Sentence                                        |
| TotalTime  | Total time to correct answer                    |
| Question   | Question (NULL if none)                         |
| Resp       | Answer                                          |
| Acc        | Whether or not answer was correct (NULL if N/A) |
| RespRT     | Time taken to answer.                           |

## How many participants do you have data for total?


```{r}

n_distinct(d$Group)

```


To determine the number of participants in this study, I used a formula to count the number of distinct values in the 'Hash' column, which is the participant identifier column. I specifically drew from the dataset that

.........


```{r}
df_all <- read.csv(here("data/delong maze 40Ss.csv"),
  header = 1, sep = ",", comment.char = "#", strip.white = T,
  col.names = c("Index", "Time", "Counter", "Hash", "Owner", 
                "Controller", "Item", "Element", "Type", "Group", 
                "FieldName", "Value", "WordNum", "Word", "Alt", 
                "WordOn", "CorrWord", "RT", "Sent", "TotalTime", 
                "Question", "Resp", "Acc", "RespRT")
)
```


## How many rows of data remained after removing the trials as described in the "data analysis" section? (inline code in text - discuss what kind of data you excluded!)


```{r}
df_rt <- df_all |> 
  filter(Controller == "Maze" & !str_detect(Type, "prac")) |> 
  select(1:10, 13:20) |> 
  separate(col = Type, 
           into = c("exp", "item", "expect", "position", "pos", 
                    "cloze", "art.cloze", "n.cloze"), 
           sep = "\\.", convert = TRUE, fill = "right") |> 
  mutate(WordNum = as.numeric(WordNum),
         Acc = as.numeric(as.character(recode(CorrWord, yes = "1", no = "0"))),
         n.cloze.scale =  scale(n.cloze), 
         art.cloze.scale = scale(art.cloze)) |> 
  mutate(across(where(is.character), as.factor)) |> 
  filter(item != 29) |> 
  filter(Hash != "9dAvrH0+R6a0U5adPzZSyA")
```


We excluded ....


```{r}

rt.s <- df_rt 

rt.s$rgn.fix <- rt.s$WordNum - rt.s$pos + 1
rt.s$word.num.z <- scale(rt.s$WordNum)
rt.s$word.len <- nchar(as.character(rt.s$Word))
rt.s$Altword.len <- nchar(as.character(rt.s$Alt))
# simplying by using dummy/treatment coding instead of sum coding
# 'expected' will be reference level
#contrasts(rt.s$expect) <- c(-.5,.5)

rt.s$item.expect <- paste(rt.s$item, rt.s$expect, sep=".")
rt.s.filt <- rt.s[rt.s$Hash != "gyxidIf0fqXBM7nxg2K7SQ" & rt.s$Hash != "f8dC3CkleTBP9lUufzUOyQ",]

rgn.rt.raw <- rt.s.filt %>%
  filter(rgn.fix > -4 & rgn.fix < 5) %>%
  filter(Acc == 1) %>%
  group_by(rgn.fix, expect) %>%
  summarize(n = n(), subj = length(unique(Hash)), rt = mean(RT), 
            sd = sd(RT), stderr = sd / sqrt(subj)) %>%
  as.data.frame()
rgn.rt.raw$rgn <- as.factor(recode(rgn.rt.raw$rgn.fix, "-3"="CW-3", "-2"="CW-2", "-1"="CW-1", "0"="art", "1"="n","2"="CW+1", "3"="CW+2", "4"="CW+3"))
rgn.rt.raw$rgn <- ordered(rgn.rt.raw$rgn, levels = c("CW-3", "CW-2", "CW-1", "art", "n", "CW+1", "CW+2", "CW+3"))


```

```{r}
rt.s.filt |> 
  filter(rgn.fix == 0) |> 
  group_by(Hash, expect) |> 
  summarize(RT = mean(RT, na.rm = TRUE)) |> 
  group_by(expect) |> 
  summarize(RT = mean(RT, na.rm = TRUE)) |>
  gt() |> 
  fmt_number(decimals = 0)

```

```{r}

set.seed(343)
p_parts <- rt.s.filt |> 
  filter(rgn.fix == 0) |> 
  group_by(Hash, expect) |> 
  summarize(RT = mean(RT, na.rm = TRUE)) |> 
  ggplot(aes(x=expect, y=RT, color = expect)) +
  geom_jitter(stat = "identity", width = .1, alpha = .8) +
  geom_point(stat = "summary", fun = mean, 
             shape = 4, color = "blue", size = 4) +
  labs(x = "Condition", y = "Reading Time (msec)") + 
  theme_bw()  
ggplotly(p_parts)

```

```{r}
m_lm <- lm(RT ~ expect, 
           data = filter(rt.s.filt, rgn.fix == 0))
summary(m_lm)

ggplot(filter(rt.s.filt, rgn.fix == 0), aes(x = expect, y = RT)) +
  geom_jitter(alpha = 0.5)
```

```{r}

tbl_regression(m_lm, conf.int = FALSE)

```

